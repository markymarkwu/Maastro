{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c84f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load image Python extension: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from DosePredictionDataset.ipynb\n"
     ]
    }
   ],
   "source": [
    "## TORCH LIBRARY\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchio as tio\n",
    "\n",
    "## MONAI LIBRARY\n",
    "from monai.networks.nets import BasicUNet as BU\n",
    "from monai.losses.dice import DiceLoss\n",
    "from monai.handlers import checkpoint_saver\n",
    "\n",
    "## OTHER LIBRARIES\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from dicom_contour.contour import *\n",
    "from functools import reduce\n",
    "import SimpleITK as sk\n",
    "import copy\n",
    "import itk\n",
    "from numpy import savez_compressed\n",
    "from numpy import load\n",
    "\n",
    "## WEIDGHTS & BIASES\n",
    "import wandb\n",
    "os.environ[\"WANDB_CONFIG_DIR\"] = \"/tmp\"\n",
    "from tqdm import tqdm\n",
    "\n",
    "## IMPORT OTHER CLASSES\n",
    "import import_ipynb\n",
    "import DosePredictionDataset\n",
    "\n",
    "## IGNORE WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd270e7d-abc1-4bc1-b43d-d49443fa3a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## FUNCTION FOR TRAINING\n",
    "def train(device:str,\n",
    "          npz_pathlist_patients:list,\n",
    "          epochs:list,\n",
    "          learning_rate:list,\n",
    "          dropout_rate:list,\n",
    "          batch_size:list,\n",
    "          in_channels:int,\n",
    "          val_percent: float = 0.4,\n",
    "          ):\n",
    "    ## Create dataloaders for training and validation\n",
    "    dataset = DosePredictionDataset.DosePrdictionDataset(npz_pathlist_patients)\n",
    "    val_num = int(len(dataset) * val_percent)\n",
    "    train_num = len(dataset) - val_num\n",
    "    train_set, val_set = random_split(dataset, [train_num, val_num], generator=torch.Generator().manual_seed(42)) \n",
    "    # Login wandb account\n",
    "    wandb.login() \n",
    "    # Create combinations of hyperparameters\n",
    "    param_combinations = list(itertools.product(epochs, batch_size, dropout_rate, learning_rate))\n",
    "    # Create a variable to store the best model and path to store to\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    best_param = None\n",
    "    model_save_path = \"/Users/wangyangwu/Documents/Maastro/NeuralNets/BasicUNet/saved_model/\"\n",
    "    ### ================================== TRAINING START ===================================== ###\n",
    "    print(\"TRAINING STARTS ...\")\n",
    "    for comb in param_combinations:\n",
    "        # Initiate and configure wandb runner\n",
    "        run = wandb.init(reinit=True, project=\"Basic UNet\")\n",
    "        run.config.update({\"epoch\":comb[0],\n",
    "                           \"batch_size\":comb[1],\n",
    "                           \"dropout_rate\":comb[2],\n",
    "                           \"learning_rate\":comb[3]})\n",
    "        # Create data loaders for training and validation\n",
    "        train_loader = DataLoader(train_set, shuffle=True, batch_size=run.config.batch_size)\n",
    "        val_loader = DataLoader(val_set, shuffle=False, drop_last=True, batch_size=run.config.batch_size)\n",
    "        # Create neural network model\n",
    "        net = BU(spatial_dims=3,\n",
    "                 in_channels=in_channels, \n",
    "                 out_channels=1, \n",
    "                 features=(6, 16, 32, 64, 128, 16),\n",
    "                 dropout=comb[2])\n",
    "        wandb.watch(net, log='all', log_freq=1)\n",
    "        # Set up optimizer\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=run.config.learning_rate) \n",
    "        # Create step counter\n",
    "        sample_count = 0\n",
    "        # Set up softmaxer for inputs\n",
    "        softmaxer = nn.Softmax(dim=2)    \n",
    "        \n",
    "        for epoch in tqdm(range(run.config.epoch)):\n",
    "            # Create epoch loss log variables\n",
    "            epoch_loss_train = 0\n",
    "            epoch_loss_val = 0  \n",
    "            ## ========================== TRAINING SECTION =========================== ##\n",
    "            net.train()\n",
    "            for images, masks in train_loader:\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                masks = masks.to(device=device, dtype=torch.float32)\n",
    "                # forward pass\n",
    "                image_pred = net(images)\n",
    "                train_loss = DiceLoss().forward(softmaxer(image_pred),\n",
    "                                                softmaxer(masks))\n",
    "                epoch_loss_train += train_loss.item()\n",
    "                # backword pass\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                # optimizing\n",
    "                optimizer.step()\n",
    "                sample_count += len(images)\n",
    "                # Log training loss\n",
    "                wandb.log({\"training_loss\": train_loss.item()},step=sample_count)\n",
    "            print(f\"Training loss after epoch {epoch+1}: {epoch_loss_train}\")                \n",
    "            ## ========================== VALIDATION SECTION ========================== ##\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader:\n",
    "                    images = images.to(device=device, dtype=torch.float32)\n",
    "                    masks = masks.to(device=device, dtype=torch.float32)\n",
    "                    image_pred = net(images)\n",
    "                    val_loss = DiceLoss().forward(softmaxer(image_pred),\n",
    "                                              softmaxer(masks))\n",
    "                    epoch_loss_val += val_loss.item()\n",
    "                    wandb.log({\"validation_loss\": val_loss.item()},step=sample_count)\n",
    "            print(f\"Validation loss after epoch {epoch+1}: {epoch_loss_val}\")\n",
    "            if best_val_loss >= epoch_loss_val:\n",
    "                best_val_loss = epoch_loss_val\n",
    "                best_model = copy.deepcopy(net)  \n",
    "                best_param = comb\n",
    "        run.finish()\n",
    "    print(\"TRAINING FINISHED\")\n",
    "    print(\"Best validation loss is: \", best_val_loss)\n",
    "    best_param = {'epoch':best_param[0],\n",
    "                  'batch_size':best_param[1],\n",
    "                  'dropout_rate':best_param[2],\n",
    "                  'learning_rate':comb[3]}\n",
    "    torch.save({'model_state_dict': best_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'param': best_param,\n",
    "                'loss': best_val_loss}, model_save_path+f\"best_model_{struct_types}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b70b0f1-d494-4ec5-859a-c9bd42571765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patients_data(patient_path_list:list, ROI_names:list):\n",
    "    CT_paths = []\n",
    "    dose_paths = []\n",
    "    sizes = []\n",
    "    INPUTs = []\n",
    "    DOSEs = []\n",
    "    for patient_path in patient_path_list:\n",
    "        subfolder_path = []\n",
    "        for roots, dirs, files in os.walk(patient_path):\n",
    "            subfolder_path.append(roots)\n",
    "        CT_paths += [input_path for input_path in subfolder_path if \"/CT/\" in input_path]\n",
    "        dose_paths += [input_path for input_path in subfolder_path if \"/RTDOSE/\" in input_path]\n",
    "\n",
    "    for CT_path ,dose_path in zip(CT_paths, dose_paths):\n",
    "        # ============================== align CT origin with Dose ============================ #\n",
    "        #get CT scan\n",
    "        CT = extract_images(CT_path)\n",
    "        CT_origin = np.array(list(CT.GetOrigin()))\n",
    "        spacing = np.array(CT.GetSpacing())\n",
    "        CT = sk.GetArrayFromImage(CT)\n",
    "        #get Dose map\n",
    "        DOSE = extract_images(dose_path)\n",
    "        dose_origin = np.array(DOSE.GetOrigin()[:3])\n",
    "        slicing_idx = np.absolute(np.ceil(((dose_origin-CT_origin)/spacing)))[::-1].astype(int)\n",
    "        aligned_CT = CT[slicing_idx[0]:,slicing_idx[1]:, slicing_idx[2]:]\n",
    "        # ======================= align Struct contour origin with Dose ======================= #        \n",
    "        struct_contours = get_struct_contours(CT_path, ROI_names)\n",
    "        aligned_struct_contours = [contour[slicing_idx[0]:,slicing_idx[1]:, slicing_idx[2]:] for contour in struct_contours]\n",
    "        # ========================== get X slicing from body contour ========================== #   \n",
    "        body_contour = get_struct_contours(CT_path, [\"Body1\"])[0]\n",
    "        aligned_body_contour = body_contour[slicing_idx[0]:,slicing_idx[1]:, slicing_idx[2]:]\n",
    "        X_slicing_idx = aligned_body_contour.shape[0]-1\n",
    "        while X_slicing_idx>0:\n",
    "            if np.sum(aligned_body_contour[X_slicing_idx]>0):\n",
    "                X_slicing_idx-=1\n",
    "            else:\n",
    "                break\n",
    "        # ==================================== final slicing  ==================================#   \n",
    "        aligned_CT = aligned_CT[:X_slicing_idx, :, :]\n",
    "        aligned_struct_contours = [contour[:X_slicing_idx,:,:] for contour in aligned_struct_contours]\n",
    "        aligned_struct_contours.append(aligned_CT)\n",
    "        INPUTs.append(torch.from_numpy(np.stack(aligned_struct_contours)).type(torch.float32))\n",
    "        DOSEs.append(sk.GetArrayFromImage(DOSE))\n",
    "        # =============================== add size to size list  ===============================# \n",
    "        x = aligned_CT.shape[0]\n",
    "        y = aligned_CT.shape[1]\n",
    "        z = aligned_CT.shape[2]\n",
    "        sizes.append((x,y,z))  \n",
    "    X = max([t[0] for t in sizes])\n",
    "    Y = max([t[1] for t in sizes])\n",
    "    Z = max([t[2] for t in sizes])\n",
    "    max_outdim = (X,Y,Z)\n",
    "    print(f\"Best input size is: {max_outdim}\")\n",
    "    patients_data = []\n",
    "    for inputs, dose in zip(INPUTs, DOSEs):\n",
    "        patients_data.append([crop(inputs,max_outdim), crop(dose,max_outdim,True)])   \n",
    "    return patients_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c8c85b5-ce29-43bb-8b6f-4a4d40d66b71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_struct_contours(path:str, ROI_names:list):\n",
    "    contours_list = []\n",
    "    #store dicom file\n",
    "    contour_file = get_contour_file(path)\n",
    "    contour_data = dicom.read_file(path + '/' + contour_file)\n",
    "    ROI_list = get_roi_names(contour_data)\n",
    "    target_ROI_index = []\n",
    "    for name in ROI_names:\n",
    "        for t in ROI_list:\n",
    "            if name.lower()==\"body1\" and t.lower()==\"body\":   \n",
    "                target_ROI_index.append(ROI_list.index(t))\n",
    "            elif name.lower()==t.lower():\n",
    "                target_ROI_index.append(ROI_list.index(t))\n",
    "                \n",
    "    # images, contours = get_data(path, index=target_ROI_index[0])\n",
    "    for index in target_ROI_index:\n",
    "        images, contours = get_data(path, index=index)\n",
    "        #get contour maps\n",
    "        contour_slices = [contours[i] for i in range(contours.shape[0])]\n",
    "        contour_3d = [fill_contour(c) if c.max()==1 else c for c in contour_slices]\n",
    "        contour_3d = np.stack(contour_3d)\n",
    "        contours_list.append(contour_3d)\n",
    "    return contours_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1139bf-fb51-411d-9f55-b37146cb5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTION TO EXTRACT CT AND DOSE IMAGES\n",
    "def extract_images(folder_path:str):\n",
    "    path = Path(folder_path)\n",
    "    file_ids = sk.ImageSeriesReader.GetGDCMSeriesIDs(str(path))\n",
    "    file_names = sk.ImageSeriesReader.GetGDCMSeriesFileNames(str(path), file_ids[0])\n",
    "    series_reader = sk.ImageSeriesReader()\n",
    "    series_reader.SetFileNames(file_names)\n",
    "    image_data = series_reader.Execute()\n",
    "    return image_data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31823e47-8ce8-45cb-bcf7-f4908b9136d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTION TO CROP INPUT IMAGES\n",
    "def crop(images:object, out_dim:tuple, if_dose:bool=False):\n",
    "    if if_dose:\n",
    "        padding = 0\n",
    "    else:\n",
    "        padding = -1024\n",
    "    cropper = tio.CropOrPad(target_shape=out_dim, padding_mode=padding)\n",
    "    cropped = cropper(images)\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c6176b5-0022-4bfa-9c41-3086ca62d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_npz(patient_inputs:list, patient_IDs:list):\n",
    "    save_dir = \"/Users/wangyangwu/Documents/Maastro/NeuralNets/preprocessed_data_compressed_npz/\"\n",
    "    for patient, ID in zip(patient_inputs, patient_IDs):\n",
    "        sub_save_dir = save_dir+ID+\"/\"\n",
    "        os.makedirs(sub_save_dir,exist_ok=True)\n",
    "        save_path_inputs = os.path.join(sub_save_dir, \"inputs.npz\")\n",
    "        save_path_label = os.path.join(sub_save_dir, \"label.npz\")\n",
    "        inputs = patient[0].numpy()\n",
    "        label = patient[1]\n",
    "        savez_compressed(save_path_inputs, inputs)\n",
    "        savez_compressed(save_path_label, label)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d300c9-dc80-47f4-bfc9-d90899982eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_list(top_dir:str):\n",
    "    pathlist_patients = []\n",
    "    for folder in os.listdir(top_dir):\n",
    "        folder_path = os.path.join(top_dir, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            pathlist_patients.append(folder_path)\n",
    "    return pathlist_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "650a9084-3e52-4df7-b78e-524be04ef7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_names(patient_dirs:list):\n",
    "    patient_names = [patient.split('/')[-1] for patient in patient_dirs]\n",
    "    return patient_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba90551-805b-4881-8063-d1d12f6d4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define parameters\n",
    "top_dir = \"/Users/wangyangwu/Documents/Maastro/NeuralNets/sample\"\n",
    "npz_dir = \"/Users/wangyangwu/Documents/Maastro/NeuralNets/preprocessed_data_compressed_npz/\"\n",
    "ROI_names = [\"Heart\"] \n",
    "dropout_rate = [0.5]\n",
    "learning_rate = [0.1]\n",
    "epochs = [1]\n",
    "batch_size = [1]\n",
    "in_channel = len(ROI_names)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9a0b9ce-250a-4dc7-8474-a1c6471367a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get patient dirs and patient IDs\n",
    "pathlist_patients = get_patient_list(top_dir)\n",
    "patients_IDs = get_patient_names(pathlist_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddb40416-495a-46cb-b659-38f7f13d33c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get processed patient data\n",
    "# patients_data = process_patients_data(pathlist_patients, ROI_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58b7cbb3-8520-44a3-8ce7-21ed657e03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save processed data to compressed npz files\n",
    "# save_to_npz(patients_data, patients_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc7c0c21-e2a7-43f0-9626-b4e78e2d4527",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get patient npz list\n",
    "npz_pathlist_patients = get_patient_list(npz_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad71ab1-e27a-4689-9d95-77a210e0b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"cpu\", npz_pathlist_patients, epochs, learning_rate, dropout_rate, batch_size, in_channel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14dec6-38c0-4539-b013-2ef271700589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
