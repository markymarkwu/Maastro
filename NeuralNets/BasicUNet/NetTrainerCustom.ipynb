{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c84f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load image Python extension: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from DosePredictionDataset.ipynb\n"
     ]
    }
   ],
   "source": [
    "## TORCH LIBRARY\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "## MONAI LIBRARY\n",
    "from monai.networks.nets import BasicUNet as BU\n",
    "from monai.losses.dice import DiceLoss\n",
    "from monai.handlers import checkpoint_saver\n",
    "\n",
    "## OTHER LIBRARIES\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from dicom_contour.contour import *\n",
    "from functools import reduce\n",
    "import SimpleITK as sk\n",
    "import copy\n",
    "\n",
    "## WEIDGHTS & BIASES\n",
    "import wandb\n",
    "os.environ[\"WANDB_CONFIG_DIR\"] = \"/tmp\"\n",
    "from tqdm import tqdm\n",
    "\n",
    "## IMPORT OTHER CLASSES\n",
    "import import_ipynb\n",
    "import DosePredictionDataset\n",
    "\n",
    "## IGNORE WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd270e7d-abc1-4bc1-b43d-d49443fa3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTION FOR TRAINING\n",
    "def train(device:str,\n",
    "          input_dir:list,\n",
    "          struct_types:list,\n",
    "          epochs:list,\n",
    "          learning_rate:list,\n",
    "          dropout_rate:list,\n",
    "          batch_size:list,\n",
    "          out_dim:tuple,\n",
    "          val_percent: float = 0.4,\n",
    "          ):\n",
    "    ## Create dataloaders for training and validation\n",
    "    dataset = DosePredictionDataset.DosePrdictionDataset(input_dir, struct_types, out_dim)\n",
    "    val_num = int(len(dataset) * val_percent)\n",
    "    train_num = len(dataset) - val_num\n",
    "    train_set, val_set = random_split(dataset, [train_num, val_num], generator=torch.Generator().manual_seed(42)) \n",
    "    # Login wandb account\n",
    "    wandb.login() \n",
    "    # Create combinations of hyperparameters\n",
    "    param_combinations = list(itertools.product(epochs, batch_size, dropout_rate, learning_rate))\n",
    "    # Create a variable to store the best model and path to store to\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    best_param = None\n",
    "    model_save_path = \"/Users/wangyangwu/Documents/Maastro/NeuralNets/BasicUNet/saved_model/\"\n",
    "    ### ================================== TRAINING START ===================================== ###\n",
    "    print(\"TRAINING STARTS ...\")\n",
    "    for comb in param_combinations:\n",
    "        # Initiate and configure wandb runner\n",
    "        run = wandb.init(reinit=True, project=\"Basic UNet\")\n",
    "        run.config.update({\"epoch\":comb[0],\n",
    "                           \"batch_size\":comb[1],\n",
    "                           \"dropout_rate\":comb[2],\n",
    "                           \"learning_rate\":comb[3]})\n",
    "        # Create data loaders for training and validation\n",
    "        train_loader = DataLoader(train_set, shuffle=True, batch_size=run.config.batch_size)\n",
    "        val_loader = DataLoader(val_set, shuffle=False, drop_last=True, batch_size=run.config.batch_size)\n",
    "        # Create neural network model\n",
    "        net = BU(spatial_dims=3,\n",
    "                 in_channels=len(struct_types)+1, \n",
    "                 out_channels=1, \n",
    "                 features=(6, 16, 32, 64, 128, 16),\n",
    "                 dropout=comb[2])\n",
    "        wandb.watch(net, log='all', log_freq=1)\n",
    "        # Set up optimizer\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=run.config.learning_rate) \n",
    "        # Create step counter\n",
    "        sample_count = 0\n",
    "        # Set up softmaxer for inputs\n",
    "        softmaxer = nn.Softmax(dim=2)    \n",
    "        \n",
    "        for epoch in tqdm(range(run.config.epoch)):\n",
    "            # Create epoch loss log variables\n",
    "            epoch_loss_train = 0\n",
    "            epoch_loss_val = 0  \n",
    "            ## ========================== TRAINING SECTION =========================== ##\n",
    "            net.train()\n",
    "            for images, masks in train_loader:\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                masks = masks.to(device=device, dtype=torch.float32)\n",
    "                # forward pass\n",
    "                image_pred = net(images)\n",
    "                train_loss = DiceLoss().forward(softmaxer(image_pred),\n",
    "                                                softmaxer(masks))\n",
    "                epoch_loss_train += train_loss.item()\n",
    "                # backword pass\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                print(\"backward\")\n",
    "                # optimizing\n",
    "                optimizer.step()\n",
    "                sample_count += len(images)\n",
    "                # Log training loss\n",
    "                wandb.log({\"training_loss\": train_loss.item()},step=sample_count)\n",
    "            print(f\"Training loss after epoch {epoch+1}: {epoch_loss_train}\")                \n",
    "            ## ========================== VALIDATION SECTION ========================== ##\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader:\n",
    "                    images = images.to(device=device, dtype=torch.float32)\n",
    "                    masks = masks.to(device=device, dtype=torch.float32)\n",
    "                    image_pred = net(images)\n",
    "                    val_loss = DiceLoss().forward(softmaxer(image_pred),\n",
    "                                              softmaxer(masks))\n",
    "                    epoch_loss_val += val_loss.item()\n",
    "                    wandb.log({\"validation_loss\": val_loss.item()},step=sample_count)\n",
    "            print(f\"Validation loss after epoch {epoch+1}: {epoch_loss_val}\")\n",
    "            if best_val_loss >= epoch_loss_val:\n",
    "                best_val_loss = epoch_loss_val\n",
    "                best_model = copy.deepcopy(net)  \n",
    "                best_param = comb\n",
    "        run.finish()\n",
    "    print(\"TRAINING FINISHED\")\n",
    "    print(\"Best validation loss is: \", best_val_loss)\n",
    "    torch.save({'model_state_dict': best_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'param': best_param,\n",
    "                'loss': best_val_loss}, model_save_path+f\"best_model_{struct_types}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "810f6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## FUNCTION TO FIND THE BEST SIZE OF INPUT AND OUTPUT\n",
    "# def find_best_outdim(ROI_names:list, patient_path_list:list):\n",
    "# outdim_list = []\n",
    "# CT_paths = []\n",
    "# dose_paths = []\n",
    "# sizes = []\n",
    "# #get all CT paths of all patients\n",
    "# for patient_path in patient_path_list:\n",
    "#     subfolder_path = []\n",
    "#     for roots, dirs, files in os.walk(patient_path):\n",
    "#         subfolder_path.append(roots)\n",
    "#     CT_paths += [input_path for input_path in subfolder_path if \"/CT/\" in input_path]\n",
    "#     dose_paths += [input_path for input_path in subfolder_path if \"/RTDOSE/\" in input_path]\n",
    "# #loop through all CT paths and get sizes of masks\n",
    "# for path in CT_paths:\n",
    "#     masks = []\n",
    "#     #store dicom file\n",
    "#     contour_file = get_contour_file(path)\n",
    "#     contour_data = dicom.read_file(path + '/' + contour_file)\n",
    "#     ROI_list = get_roi_names(contour_data)\n",
    "#     print(ROI_list)\n",
    "#     target_ROI_index = [ROI_list.index(r) for r in ROI_names]\n",
    "#     for index in target_ROI_index:\n",
    "#         images, contours = get_data(path, index=index)\n",
    "#         #get contour maps\n",
    "#         contour_slices = [contours[i] for i in range(contours.shape[0])]\n",
    "#         contour_3d = [fill_contour(c) if c.max()==1 else c for c in contour_slices]\n",
    "#         contour_3d = np.stack(contour_3d)\n",
    "#         masks.append(contour_3d)\n",
    "#     added_mask = reduce(lambda a, b: a+b, masks) \n",
    "#     cropped_added_mask = crop_zeros(added_mask)\n",
    "#     ## filter sizes of noise data\n",
    "#     size_original = added_mask.shape[0]*added_mask.shape[1]*added_mask.shape[2]\n",
    "#     size_cropped = cropped_added_mask.shape[0]*cropped_added_mask.shape[1]*cropped_added_mask.shape[2]\n",
    "#     if size_original/size_cropped>2:\n",
    "#         sizes.append(cropped_added_mask.shape)\n",
    "# for path in dose_paths:\n",
    "#     file_ids = sk.ImageSeriesReader.GetGDCMSeriesIDs(str(path))\n",
    "#     file_names = sk.ImageSeriesReader.GetGDCMSeriesFileNames(str(path), file_ids[0])\n",
    "#     series_reader = sk.ImageSeriesReader()\n",
    "#     series_reader.SetFileNames(file_names)\n",
    "#     image_data = series_reader.Execute()\n",
    "#     dose = sk.GetArrayFromImage(image_data)\n",
    "#     sizes.append(dose[0].shape)\n",
    "# #get the maximum x,y,z\n",
    "# x,y,z = 0,0,0\n",
    "# x = max([t[0] for t in sizes])\n",
    "# y = max([t[1] for t in sizes])\n",
    "# z = max([t[2] for t in sizes])\n",
    "# return (x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928cd7eb-43ee-4834-a888-8246f25db450",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTION TO FIND THE BEST SIZE OF INPUT AND OUTPUT BASED ON LUNG AND BODY CONTOUR\n",
    "def find_best_outdim(patient_path_list:list):\n",
    "    outdim_list = []\n",
    "    CT_paths = []\n",
    "    dose_paths = []\n",
    "    sizes = []\n",
    "    #get all CT paths of all patients\n",
    "    for patient_path in patient_path_list:\n",
    "        subfolder_path = []\n",
    "        for roots, dirs, files in os.walk(patient_path):\n",
    "            subfolder_path.append(roots)\n",
    "        CT_paths += [input_path for input_path in subfolder_path if \"/CT/\" in input_path]\n",
    "        dose_paths += [input_path for input_path in subfolder_path if \"/RTDOSE/\" in input_path]\n",
    "    #loop through all CT paths and get sizes of masks\n",
    "    for path in CT_paths:\n",
    "        masks = []\n",
    "        #store dicom file\n",
    "        contour_file = get_contour_file(path)\n",
    "        contour_data = dicom.read_file(path + '/' + contour_file)\n",
    "        ROI_list = get_roi_names(contour_data)\n",
    "        #get body and lung contours\n",
    "        body_index = [i for i in range(len(ROI_list)) if \"body\" in ROI_list[i].lower()][0]\n",
    "        lung_index = [i for i in range(len(ROI_list)) if \"lungs-gtv\" in ROI_list[i].lower()][0]\n",
    "        body_images, body_contours = get_data(path, index=body_index)\n",
    "        lung_images, lung_contours = get_data(path, index=lung_index)\n",
    "        #get contour maps\n",
    "        body_contour_slices = [body_contours[i] for i in range(body_contours.shape[0])]\n",
    "        body_contour_3d = [fill_contour(c) if c.max()==1 else c for c in body_contour_slices]\n",
    "        body_contour_3d = np.stack(body_contour_3d)\n",
    "        lung_contour_slices = [lung_contours[i] for i in range(lung_contours.shape[0])]\n",
    "        lung_contour_3d = [fill_contour(c) if c.max()==1 else c for c in lung_contour_slices]\n",
    "        lung_contour_3d = np.stack(lung_contour_3d)\n",
    "        #get cropped contours\n",
    "        body_cropped_added_mask = crop_zeros(body_contour_3d)\n",
    "        lung_cropped_added_mask = crop_zeros(lung_contour_3d)\n",
    "        #get size\n",
    "        sizes.append((lung_cropped_added_mask.shape[0],\n",
    "                      body_cropped_added_mask.shape[1], \n",
    "                      body_cropped_added_mask.shape[2]))\n",
    "    for path in dose_paths:\n",
    "        file_ids = sk.ImageSeriesReader.GetGDCMSeriesIDs(str(path))\n",
    "        file_names = sk.ImageSeriesReader.GetGDCMSeriesFileNames(str(path), file_ids[0])\n",
    "        series_reader = sk.ImageSeriesReader()\n",
    "        series_reader.SetFileNames(file_names)\n",
    "        image_data = series_reader.Execute()\n",
    "        dose = sk.GetArrayFromImage(image_data)\n",
    "        sizes.append(dose[0].shape)\n",
    "    #get the maximum x,y,z\n",
    "    x,y,z = 0,0,0\n",
    "    x = max([t[0] for t in sizes])\n",
    "    y = max([t[1] for t in sizes])\n",
    "    z = max([t[2] for t in sizes])\n",
    "    return (x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b7de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTION TO CROP ZEROS IN AN ARRAY\n",
    "def crop_zeros(ndarray):\n",
    "    valid_data_coords = np.argwhere(ndarray)\n",
    "    begin_nd_corners = valid_data_coords.min(axis=0)\n",
    "    finish_nd_corners = valid_data_coords.max(axis=0) + 1\n",
    "    ndslice = tuple(slice(begin, finish) for (begin, finish) in zip(begin_nd_corners, finish_nd_corners))\n",
    "    return ndarray[ndslice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba90551-805b-4881-8063-d1d12f6d4142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for the best output dimension ...\n",
      "Best dimension is :  (117, 295, 511)\n"
     ]
    }
   ],
   "source": [
    "top_dir = \"/Users/wangyangwu/Documents/Maastro/NeuralNets/sample\"\n",
    "pathlist_patients = []\n",
    "for folder in os.listdir(top_dir):\n",
    "    folder_path = os.path.join(top_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        pathlist_patients.append(folder_path)          \n",
    "print(\"Looking for the best output dimension ...\")\n",
    "out_dim = find_best_outdim(pathlist_patients)\n",
    "print(\"Best dimension is : \",out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7ec15-15c3-45a3-9e76-be4ba44f31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_names = [\"Heart\"]  \n",
    "dropout_rate = [0.5]\n",
    "learning_rate = [0.1]\n",
    "epochs = [1]\n",
    "batch_size = [1]\n",
    "train(\"cpu\", pathlist_patients, ROI_names, epochs, learning_rate, dropout_rate, batch_size, out_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad71ab1-e27a-4689-9d95-77a210e0b069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0ec73-578f-4492-9576-f160fbc474e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
