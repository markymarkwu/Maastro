{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c84f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load image Python extension: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from DosePredictionDataset.ipynb\n"
     ]
    }
   ],
   "source": [
    "## TORCH LIBRARY\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchio as tio\n",
    "\n",
    "## MONAI LIBRARY\n",
    "from monai.networks.nets import BasicUNet\n",
    "from monai.networks.nets import VNet\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses.dice import DiceLoss\n",
    "from monai.handlers import checkpoint_saver\n",
    "\n",
    "## OTHER LIBRARIES\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from dicom_contour.contour import *\n",
    "from functools import reduce\n",
    "import SimpleITK as sk\n",
    "import copy\n",
    "import itk\n",
    "from numpy import savez_compressed\n",
    "from numpy import load\n",
    "\n",
    "## WEIDGHTS & BIASES\n",
    "import wandb\n",
    "os.environ[\"WANDB_CONFIG_DIR\"] = \"/tmp\"\n",
    "from tqdm import tqdm\n",
    "\n",
    "## IMPORT OTHER CLASSES\n",
    "import import_ipynb\n",
    "import DosePredictionDataset\n",
    "\n",
    "## IGNORE WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd270e7d-abc1-4bc1-b43d-d49443fa3a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MAIN TRAINING FUNCTION\n",
    "def train(device:str,\n",
    "          npz_pathlist_patients:list,\n",
    "          epochs:list,\n",
    "          learning_rate:list,\n",
    "          dropout_rate:list,\n",
    "          batch_size:list,\n",
    "          ROI_names:list,\n",
    "          val_percent: float = 0.4,\n",
    "          ):\n",
    "    ## Create dataloaders for training and validation\n",
    "    dataset = DosePredictionDataset.DosePrdictionDataset(npz_pathlist_patients)\n",
    "    val_num = int(len(dataset) * val_percent)\n",
    "    train_num = len(dataset) - val_num\n",
    "    train_set, val_set = random_split(dataset, [train_num, val_num], generator=torch.Generator().manual_seed(42)) \n",
    "    # Login wandb account\n",
    "    wandb.login() \n",
    "    # Create combinations of hyperparameters\n",
    "    param_combinations = list(itertools.product(epochs, batch_size, dropout_rate, learning_rate))\n",
    "    # Create a variable to store the best model and path to store to\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    best_param = None\n",
    "    model_save_path = \"/Users/wangyangwu/Documents/Maastro/NeuralNets/BasicUNet/saved_model/\"\n",
    "    net = None\n",
    "    ### ================================== TRAINING START ===================================== ###\n",
    "    print(\"TRAINING STARTS ...\")\n",
    "    for comb in param_combinations:\n",
    "        # Initiate and configure wandb runner\n",
    "        run = wandb.init(reinit=True, project=\"Maastro\")\n",
    "        #Create neural network model\n",
    "        net = BasicUNet(spatial_dims=3,\n",
    "                 in_channels=len(ROI_names)+1, \n",
    "                 out_channels=1, \n",
    "                 features=(2, 2, 4, 8, 16, 2),\n",
    "                 dropout=comb[2])\n",
    "        # net = UNet(spatial_dims=3,\n",
    "        #            in_channels=len(ROI_names)+1, \n",
    "        #            out_channels=1,\n",
    "        #            channels=(1, 2, 4, 8, 16),\n",
    "        #            strides=(1,1,1,1))\n",
    "        run.config.update({\"epoch\":comb[0],\n",
    "                           \"batch_size\":comb[1],\n",
    "                           \"dropout_rate\":comb[2],\n",
    "                           \"learning_rate\":comb[3],\n",
    "                           \"Input\":str(ROI_names),\n",
    "                           \"Model\":net.__class__.__name__})\n",
    "        wandb.watch(net, log='all', log_freq=1)\n",
    "        train_loader = DataLoader(train_set, shuffle=True, batch_size=run.config.batch_size)\n",
    "        val_loader = DataLoader(val_set, shuffle=False, drop_last=True, batch_size=run.config.batch_size)\n",
    "        # Set up optimizer\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=run.config.learning_rate) \n",
    "        # Create step counter\n",
    "        sample_count = 0 \n",
    "        cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        for epoch in tqdm(range(run.config.epoch)):\n",
    "            # Create epoch loss log variables\n",
    "            epoch_loss_train = 0\n",
    "            epoch_loss_val = 0  \n",
    "            ## ========================== TRAINING SECTION =========================== ##\n",
    "            net.train()\n",
    "            for images, masks in train_loader:\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                masks = masks.to(device=device, dtype=torch.float32)\n",
    "                # forward pass\n",
    "                image_pred = net(images)\n",
    "                train_loss = DiceLoss().forward(normalize(image_pred), normalize_dose(masks))\n",
    "                epoch_loss_train += train_loss.item()\n",
    "                # backword pass\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                # optimizing\n",
    "                optimizer.step()\n",
    "                sample_count += len(images)\n",
    "                # Log training loss\n",
    "                wandb.log({\"training_loss\": train_loss.item(),\n",
    "                           \"epoch\":epoch+1},\n",
    "                          step=sample_count)\n",
    "            print(f\"Training loss after epoch {epoch+1}: {epoch_loss_train*run.config.batch_size/train_num}\")                \n",
    "            ## ========================== VALIDATION SECTION ========================== ##\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader:\n",
    "                    images = images.to(device=device, dtype=torch.float32)\n",
    "                    masks = masks.to(device=device, dtype=torch.float32)\n",
    "                    image_pred = net(images)\n",
    "                    val_loss = DiceLoss().forward(normalize(image_pred), normalize_dose(masks))\n",
    "                    epoch_loss_val += val_loss.item()\n",
    "                    wandb.log({\"validation_loss\": val_loss.item(),\n",
    "                               \"epoch\":epoch+1},\n",
    "                              step=sample_count)\n",
    "            print(f\"Validation loss after epoch {epoch+1}: {epoch_loss_val}\")\n",
    "            if best_val_loss >= epoch_loss_val:\n",
    "                best_val_loss = epoch_loss_val\n",
    "                best_model = copy.deepcopy(net)  \n",
    "                best_param = comb\n",
    "        run.finish()\n",
    "    print(\"TRAINING FINISHED\")\n",
    "    print(\"Best validation loss is: \", best_val_loss)\n",
    "    best_param = {'epoch':best_param[0],\n",
    "                  'batch_size':best_param[1],\n",
    "                  'dropout_rate':best_param[2],\n",
    "                  'learning_rate':comb[3]}\n",
    "    torch.save({'model_state_dict': best_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'param': best_param,\n",
    "                'loss': best_val_loss}, model_save_path+f\"{net.__class__.__name__}_{ROI_names}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b70b0f1-d494-4ec5-859a-c9bd42571765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PREPROCESS DATA INCLUDING ORIGIN ALIGNMENT AND CROPPING\n",
    "def process_patients_data(patient_path_list:list, ROI_names:list):\n",
    "    CT_paths = []\n",
    "    dose_paths = []\n",
    "    sizes = []\n",
    "    INPUTs = []\n",
    "    DOSEs = []\n",
    "    for patient_path in patient_path_list:\n",
    "        subfolder_path = []\n",
    "        for roots, dirs, files in os.walk(patient_path):\n",
    "            subfolder_path.append(roots)\n",
    "        CT_paths += [input_path for input_path in subfolder_path if \"/CT/\" in input_path]\n",
    "        dose_paths += [input_path for input_path in subfolder_path if \"/RTDOSE/\" in input_path]\n",
    "\n",
    "    for CT_path ,dose_path in zip(CT_paths, dose_paths):\n",
    "        # ============================== align CT origin with Dose ============================ #\n",
    "        #get CT scan, origin, and spacing\n",
    "        CT = get_CT_image(CT_path)\n",
    "        CT_origin = np.array(list(CT.GetOrigin()))[::-1]\n",
    "        CT_spacing = np.array(CT.GetSpacing())[::-1]\n",
    "        CT = sk.GetArrayFromImage(CT)\n",
    "        #get Dose map, origin, spacing and GridScaling\n",
    "        DOSE = get_RTDose_image(dose_path)\n",
    "        DOSE_origin = np.array(list(DOSE.GetOrigin()))[::-1]\n",
    "        DOSE_spacing = np.array(DOSE.GetSpacing())[::-1]\n",
    "        DOSE_GridScaling = float(DOSE.GetMetaData('3004|000e'))\n",
    "        #define slicing based on origin\n",
    "        origin_difference = list(map(lambda x,y: x-y if(x-y>=0) else 0, DOSE_origin, CT_origin))\n",
    "        slicing_idx = (origin_difference/CT_spacing).astype(int)\n",
    "        #align CT and Dose map s.t they have the same origin\n",
    "        aligned_CT = CT[slicing_idx[0]:,slicing_idx[1]:, slicing_idx[2]:]\n",
    "        # fig, ax = plt.subplots(2,3,figsize=(30, 10))\n",
    "        # ax[0][0].imshow(aligned_CT[50])\n",
    "        # ax[0][1].imshow(aligned_CT[:,80,:])\n",
    "        # ax[0][2].imshow(aligned_CT[:,:,150])\n",
    "        # ======================= align Struct contour origin with Dose ======================= #        \n",
    "        struct_contours = get_struct_contours(CT_path, ROI_names)\n",
    "        aligned_struct_contours = [contour[slicing_idx[0]:,slicing_idx[1]:, slicing_idx[2]:] for contour in struct_contours]\n",
    "        # ========================== get X slicing from body contour ========================== #   \n",
    "        body_contour = get_struct_contours(CT_path, [\"Body1\"])[0] \n",
    "        lung_contour = get_struct_contours(CT_path, [\"Lungs-GTV\"])[0]\n",
    "        aligned_body_contour = body_contour[slicing_idx[0]:,slicing_idx[1]:, slicing_idx[2]:]\n",
    "        aligned_lung_contour = lung_contour[slicing_idx[0]:,slicing_idx[1]:, slicing_idx[2]:]\n",
    "        X_slicing_idx = aligned_lung_contour.shape[0]-1\n",
    "        Y_slicing_idx = aligned_body_contour.shape[1]-1\n",
    "        Z_slicing_idx = aligned_body_contour.shape[2]-1\n",
    "        X_slicing_idx = min(list(map(lambda x:x-1 if(np.mean(aligned_lung_contour[x])==0 and np.mean(aligned_lung_contour[x-1])>0) else 10000, range(X_slicing_idx,0,-1))))\n",
    "        Y_slicing_idx = min(list(map(lambda y:y-1 if(np.mean(aligned_body_contour[:,y,:])==0 and np.mean(aligned_body_contour[:,y-1,:])>0) else 10000, range(Y_slicing_idx,0,-1))))\n",
    "        Z_slicing_idx = min(list(map(lambda z:z-1 if(np.mean(aligned_body_contour[:,:,z])==0 and np.mean(aligned_body_contour[:,:,z-1])>0) else 10000, range(Z_slicing_idx,0,-1))))        \n",
    "        # ==================================== final slicing  ==================================#   \n",
    "        aligned_CT = aligned_CT[:X_slicing_idx, :Y_slicing_idx, :Z_slicing_idx]\n",
    "        # ax[1][0].imshow(aligned_CT[50,:,:])\n",
    "        # ax[1][1].imshow(aligned_CT[:,50,:])\n",
    "        # ax[1][2].imshow(aligned_CT[:,:,150])\n",
    "        aligned_struct_contours = [contour[:X_slicing_idx,:Y_slicing_idx,:Z_slicing_idx] for contour in aligned_struct_contours]\n",
    "        aligned_struct_contours.append(aligned_CT)\n",
    "        resampled_CT = resample(torch.from_numpy(np.stack(aligned_struct_contours)).type(torch.float32), DOSE_spacing/CT_spacing)\n",
    "        dose_map = np.stack([sk.GetArrayFromImage(DOSE)*DOSE_GridScaling])\n",
    "        INPUTs.append(resampled_CT)\n",
    "        DOSEs.append(dose_map)\n",
    "        # =============================== add size to size list  ===============================# \n",
    "        x = max(resampled_CT.shape[1], dose_map.shape[1])\n",
    "        y = max(resampled_CT.shape[2], dose_map.shape[2])\n",
    "        z = max(resampled_CT.shape[3], dose_map.shape[3])\n",
    "        sizes.append((x,y,z)) \n",
    "           \n",
    "    X = max([t[0] for t in sizes])\n",
    "    Y = max([t[1] for t in sizes])\n",
    "    Z = max([t[2] for t in sizes])\n",
    "    max_outdim = (X,Y,Z)\n",
    "    print(f\"Best input size is: {max_outdim}\")\n",
    "    patients_data = []\n",
    "    for inputs, dose in zip(INPUTs, DOSEs):\n",
    "        patients_data.append([pad(inputs,max_outdim), pad(dose,max_outdim,True)])   \n",
    "    return patients_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c8c85b5-ce29-43bb-8b6f-4a4d40d66b71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## GET STRUCTURE CONTOURS FROM FILES\n",
    "def get_struct_contours(path:str, ROI_names:list):\n",
    "    contours_list = []\n",
    "    #store dicom file\n",
    "    contour_file = get_contour_file(path)\n",
    "    contour_data = dicom.read_file(path + '/' + contour_file)\n",
    "    ROI_list = get_roi_names(contour_data)\n",
    "    # print(ROI_list)\n",
    "    target_ROI_index = []\n",
    "    for name in ROI_names:\n",
    "        for t in ROI_list:\n",
    "            if name.lower()==\"body1\" and t.lower()==\"body\":   \n",
    "                target_ROI_index.append(ROI_list.index(t))\n",
    "            elif name.lower()==\"lungs-gtv\" and t.lower()==\"lungs-gtv1\":\n",
    "                target_ROI_index.append(ROI_list.index(t))\n",
    "            elif name.lower()==t.lower():\n",
    "                target_ROI_index.append(ROI_list.index(t))\n",
    "                \n",
    "    # images, contours = get_data(path, index=target_ROI_index[0])\n",
    "    for index in target_ROI_index:\n",
    "        images, contours = get_data(path, index=index)\n",
    "        #get contour maps\n",
    "        contour_slices = [contours[i] for i in range(contours.shape[0])]\n",
    "        contour_3d = [fill_contour(c) if c.max()==1 else c for c in contour_slices]\n",
    "        contour_3d = np.stack(contour_3d)\n",
    "        contours_list.append(contour_3d)\n",
    "    return contours_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1139bf-fb51-411d-9f55-b37146cb5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## READ CT DICOM SERIES\n",
    "def get_CT_image(folder_path:str):\n",
    "    path = Path(folder_path)\n",
    "    file_ids = sk.ImageSeriesReader.GetGDCMSeriesIDs(str(path))\n",
    "    file_names = sk.ImageSeriesReader.GetGDCMSeriesFileNames(str(path), file_ids[0])\n",
    "    series_reader = sk.ImageSeriesReader()\n",
    "    series_reader.SetFileNames(file_names)\n",
    "    image_data = series_reader.Execute()\n",
    "    return image_data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9724ba9c-2e61-4500-958e-73042c9ceba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## READ RTDOSE\n",
    "def get_RTDose_image(dose_path):   \n",
    "    dose_file_path = [os.path.join(dose_path, f) for f in os.listdir(dose_path)][0]\n",
    "    file_reader = sk.ImageFileReader()\n",
    "    file_reader.SetFileName(dose_file_path)\n",
    "    dose_image = file_reader.Execute()\n",
    "    return dose_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31823e47-8ce8-45cb-bcf7-f4908b9136d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CROP INPUT IMAGES\n",
    "def pad(images:object, out_dim:tuple, if_dose:bool=False):\n",
    "    X_fin = out_dim[0] - images.shape[1]\n",
    "    Y_fin = out_dim[1] - images.shape[2]\n",
    "    Z_fin = out_dim[2] - images.shape[3]\n",
    "    if if_dose:\n",
    "        padding = 0\n",
    "        padder = tio.Pad((0,X_fin,0,Y_fin,0,Z_fin), padding_mode=padding)\n",
    "        padded = padder(images)\n",
    "    else:\n",
    "        chunks = torch.chunk(images, images.shape[0], 0)\n",
    "        padding_CT = float(torch.min(images[images.shape[0]-1]))\n",
    "        padding_Contour = float(torch.min(images[images.shape[0]-2]))\n",
    "        CT_padder = tio.Pad((0,X_fin,0,Y_fin,0,Z_fin), padding_mode=padding_CT)\n",
    "        Contour_padder = tio.Pad((0,X_fin,0,Y_fin,0,Z_fin), padding_mode=0)\n",
    "        chunks = torch.chunk(images, images.shape[0], 0)\n",
    "        padded = CT_padder(chunks[images.shape[0]-1])\n",
    "        for chunk in chunks[:images.shape[0]-1]:\n",
    "            padded = torch.cat((padded, Contour_padder(chunk)))\n",
    "        print(padded.shape)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29285cfa-538b-455d-b9b1-c3eb45ed1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RESAMPLE DOSE IMAGES\n",
    "def resample(dose_map:object, spacing:tuple, if_dose:bool=False):\n",
    "    resampler = tio.Resample(spacing)\n",
    "    resampled = resampler(dose_map)\n",
    "    return resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac879659-2528-4126-a794-69156275e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NORMALIZE TENSOR FOR DICE LOSS\n",
    "def normalize_dose(dose_map:torch.TensorType):\n",
    "    normalized_dose = dose_map/100\n",
    "    return normalized_dose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9995c936-2ac3-4a15-8097-5c71c871bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NORMALIZE TENSOR\n",
    "def normalize(inputs:torch.TensorType):\n",
    "    return (inputs-inputs.min())/(inputs.max()-inputs.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c6176b5-0022-4bfa-9c41-3086ca62d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE PROCESSED DATA TO COMPRESSED NPY FORMAT\n",
    "def save_to_npz(patient_inputs:list, patient_IDs:list, ROI_names:list):\n",
    "    save_dir = \"/Users/wangyangwu/Documents/Maastro/NeuralNets/Processed_data/preprocessed_data_compressed_npz\"+str(ROI_names)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for patient, ID in zip(patient_inputs, patient_IDs):\n",
    "        sub_save_dir = save_dir+\"/\"+ID+\"/\"\n",
    "        os.makedirs(sub_save_dir,exist_ok=True)\n",
    "        save_path_inputs = os.path.join(sub_save_dir, \"inputs.npz\")\n",
    "        save_path_label = os.path.join(sub_save_dir, \"label.npz\")\n",
    "        inputs = patient[0].numpy()\n",
    "        label = patient[1]\n",
    "        savez_compressed(save_path_inputs, inputs)\n",
    "        savez_compressed(save_path_label, label)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d300c9-dc80-47f4-bfc9-d90899982eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET PATH LIST FOR ALL PATIENTS \n",
    "def get_patient_list(top_dir:str):\n",
    "    pathlist_patients = []\n",
    "    for folder in os.listdir(top_dir):\n",
    "        folder_path = os.path.join(top_dir, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            pathlist_patients.append(folder_path)\n",
    "    return pathlist_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "650a9084-3e52-4df7-b78e-524be04ef7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET LIST OF PATIENT ID\n",
    "def get_patient_IDs(patient_dirs:list):\n",
    "    patient_IDs = [patient.split('/')[-1] for patient in patient_dirs]\n",
    "    return patient_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4096849-2cc6-463b-9af0-103ca1fd911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(top_dir:str, ROI_names:list):\n",
    "    ## get patient dirs and patient IDs\n",
    "    pathlist_patients = get_patient_list(top_dir)\n",
    "    patients_IDs = get_patient_IDs(pathlist_patients)\n",
    "    ## get processed patient data\n",
    "    patients_data = process_patients_data(pathlist_patients, ROI_names)\n",
    "    ## save processed data to compressed npz files\n",
    "    save_to_npz(patients_data, patients_IDs, ROI_names)\n",
    "    return patients_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43ccbd76-e295-4885-8751-e6eeeda14f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(patients_data:list, slice_idx1:int, slice_idx2:int, slice_idx3:int):\n",
    "    ## visualize processed data\n",
    "    fig, ax = plt.subplots(3,3,figsize=(30, 10))\n",
    "    ax[0][0].imshow(patients_data[0][0][0][slice_idx1])\n",
    "    ax[0][0].set(xlabel=\"CT scan (Axial)\")\n",
    "    ax[0][1].imshow(patients_data[0][0][1][slice_idx1])\n",
    "    ax[0][1].set(xlabel=\"contour (Axial)\")\n",
    "    ax[0][2].imshow(patients_data[0][1][0][slice_idx1])\n",
    "    ax[0][2].set(xlabel=\"Dose map (Axial)\")\n",
    "    ax[1][0].imshow(patients_data[0][0][0][:,slice_idx2,:])\n",
    "    ax[1][0].set(xlabel=\"CT scan (Cronal)\")\n",
    "    ax[1][1].imshow(patients_data[0][0][1][:,slice_idx2,:])\n",
    "    ax[1][1].set(xlabel=\"contour (Cronal)\")\n",
    "    ax[1][2].imshow(patients_data[0][1][0][:,slice_idx2,:])\n",
    "    ax[1][2].set(xlabel=\"Dose map (Cronal)\")\n",
    "    ax[2][0].imshow(patients_data[0][0][0][:,:,slice_idx3])\n",
    "    ax[2][0].set(xlabel=\"CT scan (Saggital)\")\n",
    "    ax[2][1].imshow(patients_data[0][0][1][:,:,slice_idx3])\n",
    "    ax[2][1].set(xlabel=\"contour (Saggital)\")\n",
    "    ax[2][2].imshow(patients_data[0][1][0][:,:,slice_idx3])\n",
    "    ax[2][2].set(xlabel=\"Dose map (Saggital)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ba90551-805b-4881-8063-d1d12f6d4142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define parameters\n",
    "ROI_names = [\"CTV1\"] \n",
    "top_dir = \"/Users/wangyangwu/Documents/Maastro/NeuralNets/sample\"\n",
    "npz_dir = \"/Users/wangyangwu/Documents/Maastro/NeuralNets/Processed_data/preprocessed_data_compressed_npz\"+str(ROI_names)\n",
    "dropout_rate = [0.1]\n",
    "learning_rate = [0.1]\n",
    "epochs = [3]\n",
    "batch_size = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378af8c-cd34-451c-9eee-15abe09e8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_data = process(top_dir, ROI_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26dec4da-1b56-4883-820f-034f98878e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_pathlist_patients = get_patient_list(npz_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df38ea3-8e53-4710-8033-8c988615ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(patients_data, 40,60,65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bad71ab1-e27a-4689-9d95-77a210e0b069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING STARTS ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/wangyangwu/Documents/Maastro/NeuralNets/BasicUNet/wandb/run-20220304_153301-15cfe7n8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/wwy/Maastro/runs/15cfe7n8\" target=\"_blank\">ancient-serenity-18</a></strong> to <a href=\"https://wandb.ai/wwy/Maastro\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (2, 2, 4, 8, 16, 2).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after epoch 1: 0.9676737785339355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 1/3 [00:07<00:14,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after epoch 1: 0.9344911575317383\n",
      "Training loss after epoch 2: 0.9162609875202179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 2/3 [00:13<00:06,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after epoch 2: 0.9243051409721375\n",
      "Training loss after epoch 3: 0.9017634987831116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:20<00:00,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after epoch 3: 0.9107834696769714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▅▅██</td></tr><tr><td>training_loss</td><td>██▆▃▁▆</td></tr><tr><td>validation_loss</td><td>█▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>training_loss</td><td>0.93541</td></tr><tr><td>validation_loss</td><td>0.91078</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ancient-serenity-18</strong>: <a href=\"https://wandb.ai/wwy/Maastro/runs/15cfe7n8\" target=\"_blank\">https://wandb.ai/wwy/Maastro/runs/15cfe7n8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220304_153301-15cfe7n8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FINISHED\n",
      "Best validation loss is:  0.9107834696769714\n"
     ]
    }
   ],
   "source": [
    "train(\"cpu\", \n",
    "      npz_pathlist_patients, \n",
    "      epochs, \n",
    "      learning_rate, \n",
    "      dropout_rate, \n",
    "      batch_size, \n",
    "      ROI_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14dec6-38c0-4539-b013-2ef271700589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f9ba2-7a83-44c3-901c-b8a5f9ded4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed3d11-8878-4be2-b772-2202b5e6972e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
